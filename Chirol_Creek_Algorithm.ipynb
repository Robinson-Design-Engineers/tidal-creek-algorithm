{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard loads\n",
    "import numpy as np #type:ignore\n",
    "import matplotlib.pyplot as plt #type:ignore\n",
    "from matplotlib.colors import ListedColormap #type:ignore\n",
    "import pandas as pd #type:ignore\n",
    "import os\n",
    "import json\n",
    "import h5py #type:ignore\n",
    "from skimage import morphology #type:ignore\n",
    "from skimage.morphology import skeletonize #type:ignore\n",
    "from skimage.morphology import dilation, disk # type: ignore\n",
    "from scipy import ndimage # type: ignore\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warnings\n",
    "\n",
    "\n",
    "# import specific algorithm functions\n",
    "from input_formatting import input_formatting \n",
    "from readvardef import readvardef\n",
    "from Loadlidarmaps import Loadlidarmaps\n",
    "from RemoveaboveHAT import RemoveaboveHAT\n",
    "from Creek_Repair import process_creek_mask, save_creek_mask_h5, load_creek_mask_h5, process_creek_mask_diagnostic\n",
    "from Creek_Ordering import figure_creek_skeleton, process_creek_ordering, process_creek_ordering_diagnostic\n",
    "from check_plots_step5 import plot_creek_orders, plot_creek_orders_big\n",
    "from Strahler_Correction_class import CreekNetworkAnalyzer\n",
    "from Display_Orders import process_creek_orders\n",
    "from Process_CrossSections import process_xsects, process_xsects_diagnostic\n",
    "from Process_JunctionAngles import process_junction_angles, process_junction_angles_diagnostic\n",
    "from Save_Results import process_creek_morphometry, process_creek_morphometry_diagnostic\n",
    "\n",
    "%config InlineBackend.figure_format='retina' # hig-res plots for a Retina display, uncomment while working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input filenames\n",
    "# manual input, as opposed to MATLAB script's GUI selection\n",
    "\n",
    "basename_elev = 'otc_DEM_converted_m.asc' \n",
    "basename_slope = 'otc_slope_degrees.asc'\n",
    "basename_UserVar = 'UserVar_otc.txt' \n",
    "\n",
    "filepath_input_folder = '/Users/sam/RDE Dropbox/Projects/22386.Ashleyville Marsh/WORK/CODE/Python/CHIROL_CREEK_EXTRACTION_ALGORITHM/INPUTS/'\n",
    "\n",
    "filename_elev = filepath_input_folder+basename_elev\n",
    "filename_slope = filepath_input_folder+basename_slope\n",
    "filename_UserVar = filepath_input_folder+basename_UserVar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input_formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_formatting\n",
    "# formats elevation and slope raster ascii files in to .h5\n",
    "# requires user manual input for filename of elevation and slope\n",
    "\n",
    "from input_formatting import input_formatting\n",
    "\n",
    "# check if OUTPUTS folder is created - if not, create one\n",
    "folder_path_check = \"OUTPUTS\"\n",
    "\n",
    "# Check if the folder exists\n",
    "if not os.path.exists(folder_path_check):\n",
    "    # Create the folder\n",
    "    os.makedirs(folder_path_check)\n",
    "    print(f\"Folder '{folder_path_check}' created.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_path_check}' already exists.\")\n",
    "\n",
    "print('Elevation Files:')\n",
    "# Change file names for specific site - i.e., filename = 'INPUTS/blahblah_elev.txt' or 'INPUTS/blahblah_slope.txt'\n",
    "filename_out_elev, filename_out_meta_elev = input_formatting(filename_elev)\n",
    "print('File was saved as: ', filename_out_elev)\n",
    "print('Metadata file was saved as: ', filename_out_meta_elev)\n",
    "\n",
    "print('')\n",
    "\n",
    "print('Slope Files:')\n",
    "filename_out_slope, filename_out_meta_slope = input_formatting(filename_slope)\n",
    "print('File was saved as: ', filename_out_slope)\n",
    "print('Metadata file was saved as: ', filename_out_meta_slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHIROL_CREEK_ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI and ChatGPT, reviewed by Sam Kraus 2024/09/13\n",
    "\n",
    "# import specific algorithm functions\n",
    "from readvardef import readvardef\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 1) User to select input variables\n",
    "figview = 0  # Change to 1 to see additional figures\n",
    "\n",
    "# Open User Variables instruction file\n",
    "result = readvardef('INPUTS/'+basename_UserVar)\n",
    "if result is None:\n",
    "    print(\"User aborted or error occurred.\")\n",
    "    exit()\n",
    "\n",
    "FILENAMES, PROCESSING, TIDE, THRESHOLDS, RECONNECTION = result\n",
    "\n",
    "# Unpack data from global variables\n",
    "name = FILENAMES[\"name\"]\n",
    "shortname = FILENAMES[\"shortname\"]\n",
    "elev = FILENAMES[\"elev\"]\n",
    "elevmeta = FILENAMES[\"elevmeta\"]\n",
    "slope = FILENAMES[\"slope\"]\n",
    "slopemeta = FILENAMES[\"slopemeta\"]\n",
    "\n",
    "resamplestep = PROCESSING[\"resamplestep\"]\n",
    "threshold = PROCESSING[\"threshold\"]\n",
    "detrendyn = PROCESSING[\"detrendyn\"]\n",
    "outletdetection = PROCESSING[\"outletdetection\"]\n",
    "\n",
    "HAT = TIDE[\"HAT\"]\n",
    "MHWS = TIDE[\"MHWS\"]\n",
    "MHWN = TIDE[\"MHWN\"]\n",
    "MLWS = TIDE[\"MLWS\"]\n",
    "MLWN = TIDE[\"MLWN\"]\n",
    "\n",
    "Cth = THRESHOLDS[\"Cth\"]\n",
    "Ctharea = THRESHOLDS[\"Ctharea\"]\n",
    "LZth = THRESHOLDS[\"LZth\"]\n",
    "LZtharea = THRESHOLDS[\"LZtharea\"]\n",
    "HZth = THRESHOLDS[\"HZth\"]\n",
    "HZtharea = THRESHOLDS[\"HZtharea\"]\n",
    "\n",
    "nbbreaches = RECONNECTION[\"nbbreaches\"]\n",
    "noisethreshold = RECONNECTION[\"noisethreshold\"]\n",
    "reconnect = RECONNECTION[\"reconnect\"]\n",
    "reconnectiondist = RECONNECTION[\"reconnectiondist\"]\n",
    "ordermax = RECONNECTION[\"ordermax\"]\n",
    "filtersmall1 = RECONNECTION[\"filtersmall1\"]\n",
    "filterlarge1 = RECONNECTION[\"filterlarge1\"]\n",
    "smoothing = RECONNECTION[\"smoothing\"]\n",
    "connectivity = RECONNECTION[\"connectivity\"]\n",
    "holesizeinfill = RECONNECTION[\"holesizeinfill\"]\n",
    "filtersmall2 = RECONNECTION[\"filtersmall2\"]\n",
    "filterlarge2 = RECONNECTION[\"filterlarge2\"]\n",
    "\n",
    "#  Print out the values to verify they were read correctly\n",
    "# print(\"Loaded variables:\")\n",
    "# for category in [FILENAMES, PROCESSING, TIDE, THRESHOLDS, RECONNECTION]:\n",
    "#     for key, value in category.items():\n",
    "#         print(f\"{key}: {value}\")\n",
    "\n",
    "end_time = time.time()\n",
    "# print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI and ChatGPT, reviewed by Sam Kraus 2024/09/15\n",
    "\n",
    "# import specific algorithm functions\n",
    "from Loadlidarmaps import Loadlidarmaps\n",
    "from RemoveaboveHAT import RemoveaboveHAT\n",
    "\n",
    "# Load the data\n",
    "Xs, Ys, Zs, X, Y, Z, gs, xc, yc = Loadlidarmaps(elev, elevmeta, slope, slopemeta)\n",
    "\n",
    "# Remove values above HAT\n",
    "Z, Zs, meandepth, meanslope = RemoveaboveHAT(Z, Zs, HAT, detrendyn)\n",
    "\n",
    "# Print some information about the loaded and processed data\n",
    "print(f\"Data loaded and processed:\")\n",
    "print(f\"X range: {np.min(X)} to {np.max(X)} meters\")\n",
    "print(f\"Y range: {np.min(Y)} to {np.max(Y)} meters\")\n",
    "print(f\"Z range: {np.nanmin(Z)} to {np.nanmax(Z)} meters\")\n",
    "print(f\"Mean depth: {meandepth} meters\")\n",
    "print(f\"Mean slope: {meanslope} degrees\")\n",
    "print(f\"Grid resolution: {gs} meters\")\n",
    "\n",
    "# Subsample the dataset to make mapping quicker\n",
    "# X2 = X[::resamplestep, ::resamplestep]\n",
    "# Y2 = Y[::resamplestep, ::resamplestep]\n",
    "X2 = X[::resamplestep] # was 2D in MATLAB, I guess not 2D in Python?\n",
    "Y2 = Y[::resamplestep] # was 2D in MATLAB, I guess not 2D in Python?\n",
    "Z2 = Z[::resamplestep, ::resamplestep]\n",
    "\n",
    "print(f\"Subsampled data shape: {Z2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI and ChatGPT, reviewed by Sam Kraus 2024/09/15 and 2024/10/10\n",
    "\n",
    "# Your variables\n",
    "variables_detection = {\n",
    "    \"threshold\": 1,\n",
    "    \"Zs\": Zs.tolist(),   # Convert arrays to lists to make them JSON serializable\n",
    "    \"Z\": Z.tolist(),\n",
    "    \"gs\": gs,\n",
    "    \"X\": X,\n",
    "    \"Y\": Y,\n",
    "    \"X2\": X2,\n",
    "    \"Y2\": Y2,\n",
    "    \"Z2\": Z2,\n",
    "    \"LZtharea\": LZtharea,\n",
    "    \"LZth\": LZth,\n",
    "    \"HZtharea\": HZtharea,\n",
    "    \"HZth\": HZth,\n",
    "    \"Ctharea\": Ctharea,\n",
    "    \"Cth\": Cth,\n",
    "    \"shortname\": shortname\n",
    "}\n",
    "\n",
    "# Convert all numpy arrays to lists\n",
    "variables_detection = {key: value.tolist() if isinstance(value, np.ndarray) else value for key, value in variables_detection.items()}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"variables_Creek_Detection.json\", \"w\") as f:\n",
    "    json.dump(variables_detection, f)\n",
    "\n",
    "# After running this cell, you need to run in terminal, following these steps: <br>\n",
    "# 1) If you're on macOS or Linux, make sure that Tkinter (which matplotlib uses for plotting) is properly installed. \n",
    "#     On macOS, you can install it via Homebrew using: <br>\n",
    "#     ```brew install python-tk```\n",
    "#     NOTE: Homebrew is a package manager for macOS (and Linux)\n",
    "#       that simplifies the process of installing, updating, and managing software and tools on your system.\n",
    "# 2) Open terminal (Command Prompt in Windows)\n",
    "# 3) Change current directory to folder containing creek extraction .py files - the \"~\" is to reference your user local folder\n",
    "#     (spaces in filepath need to be preceded by a single backslash \\ to not break up continuous filepath): <br>\n",
    "#      ```cd ~/RDE\\ Dropbox/Projects/22386.Ashleyville\\ Marsh/WORK/CODE/Python/CHIROL_CREEK_EXTRACTION_ALGORITHM```\n",
    "# 4) Run .py file:  <br>\n",
    "#     ```python Creek_Detection.py```\n",
    "# 5) Plots should appear in python GUI windows - you can adjust plot positioning in this window, and save the figures. \n",
    "#       If the threshold value is 1, you will be prompted to click GUI plots of slope and hypsometry.\n",
    "# 6) As instructed in terminal print statement, press Enter (return) key to close plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Step 3 processed variables from the JSON file\n",
    "with open(f\"OUTPUTS/{shortname}_processed_variables_Creek_Detection.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "creek = variables[\"creek\"]\n",
    "CumArea = variables[\"CumArea\"]\n",
    "binrange = variables[\"binrange\"]\n",
    "CumAreas = variables[\"CumAreas\"]\n",
    "binranges = variables[\"binranges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI and ChatGPT, reviewed by Sam Kraus 2024/10/14\n",
    "\n",
    "# import specific algorithm functions\n",
    "from Creek_Repair import process_creek_mask, save_creek_mask_h5, load_creek_mask_h5, process_creek_mask_diagnostic\n",
    "\n",
    "# load raw creek mask from Step 3\n",
    "with h5py.File(f'OUTPUTS/{shortname}_creekmask_raw.h5', 'r') as hf:\n",
    "    creekmask_raw = hf['creekmask_raw'][:]\n",
    "    \n",
    "# execute functions in Creek_Repair.py and process_creek_mask function\n",
    "creekmask = process_creek_mask(creekmask_raw, reconnect, noisethreshold, reconnectiondist, connectivity,\n",
    "                                    filtersmall1, filterlarge1, smoothing, filtersmall2, filterlarge2, holesizeinfill)\n",
    "# ^the process_creek_mask function inputs differ from the .py file due to use of underscores in .py as opposed to no underscores in .ipynb\n",
    "save_creek_mask_h5(creekmask, 'OUTPUTS/{}_creekmask.h5'.format(shortname))\n",
    "\n",
    "# # for troubleshooting issues in oversmoothing and filling operations, run diagnostic function with helpful print statements and plots:\n",
    "# repaired_mask = process_creek_mask_diagnostic(creekmask_raw, reconnect, noisethreshold, reconnectiondist, connectivity,\n",
    "#                                     filtersmall1, filterlarge1, smoothing, filtersmall2, filterlarge2, holesizeinfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 5 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed line-by-line by Sam Kraus 2024/11/25\n",
    "\n",
    "# import specific algorithm functions\n",
    "from Creek_Ordering import figure_creek_skeleton, process_creek_ordering, process_creek_ordering_diagnostic\n",
    "\n",
    "# load raw creek mask from Step 4\n",
    "creekmask = load_creek_mask_h5(f'OUTPUTS/{shortname}_creekmask.h5')\n",
    "\n",
    "# prep data for functions\n",
    "skeleton = morphology.skeletonize(creekmask)\n",
    "\n",
    "# # execute functions in Creek_Ordering.py\n",
    "# STRAHLER, STRAIGHTDIST, IDXSEG, IDXBRANCH, idxbreach, xbreach, ybreach, skeleton_breached, creekorder, creekordersing, PTS, ID = process_creek_ordering(ordermax, Z, skeleton, outletdetection, nbbreaches)\n",
    "\n",
    "# diagnostic version - uncomment and run for debugging:\n",
    "results_ordering = process_creek_ordering_diagnostic(ordermax, Z, skeleton, outletdetection, nbbreaches)\n",
    "STRAHLER, STRAIGHTDIST, IDXSEG, IDXBRANCH, idxbreach, xbreach, ybreach, skeleton_breached, creekorder, creekordersing, PTS, ID = results_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from check_plots_step5 import plot_creek_orders, plot_creek_orders_big\n",
    "\n",
    "# Plot the sample data for skeleton\n",
    "fig, ax = plot_creek_orders(skeleton_breached, creekordersing)\n",
    "plt.show()\n",
    "\n",
    "# Plot the sample data\n",
    "fig, ax = plot_creek_orders_big(skeleton_breached, creekorder, ordermax, X=None, Y=None, colors=None, figsize=(10, 8), dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed by Sam Kraus 2024/12/15\n",
    "from Strahler_Correction_class import CreekNetworkAnalyzer\n",
    "\n",
    "# Your variables\n",
    "variables_correction = {\n",
    "    \"skeleton\": skeleton_breached,\n",
    "    \"X\": X,\n",
    "    \"Y\": Y,\n",
    "    \"creek_order\": creekorder,\n",
    "    \"creek_order_single\": creekordersing,\n",
    "    \"pts\": PTS,\n",
    "    \"order_max\": ordermax,\n",
    "    \"STRAHLER\": STRAHLER,\n",
    "    \"STRAIGHTDIST\": STRAIGHTDIST,\n",
    "    \"IDXBRANCH\": IDXBRANCH,\n",
    "    \"IDXSEG\": IDXSEG,\n",
    "    \"shortname\": shortname\n",
    "}\n",
    "\n",
    "# Convert all numpy arrays to lists\n",
    "variables_correction = {key: value.tolist() if isinstance(value, np.ndarray) else value for key, value in variables_correction.items()}\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"variables_Strahler_Correction.json\", \"w\") as f:\n",
    "    json.dump(variables_correction, f)\n",
    "\n",
    "# After running this cell, you need to run in terminal, following these steps: <br>\n",
    "# 1) If you're on macOS or Linux, make sure that Tkinter (which matplotlib uses for plotting) is properly installed. \n",
    "#     On macOS, you can install it via Homebrew using: <br>\n",
    "#     ```brew install python-tk```\n",
    "#     NOTE: Homebrew is a package manager for macOS (and Linux)\n",
    "#       that simplifies the process of installing, updating, and managing software and tools on your system.\n",
    "# 2) Open terminal (Command Prompt in Windows)\n",
    "# 3) Change current directory to folder containing creek correction .py files - the \"~\" is to reference your user local folder\n",
    "#     (spaces in filepath need to be preceded by a single backslash \\ to not break up continuous filepath): <br>\n",
    "#      ```cd ~/RDE\\ Dropbox/Projects/22386.Ashleyville\\ Marsh/WORK/CODE/Python/CHIROL_CREEK_EXTRACTION_ALGORITHM```\n",
    "# 4) Run .py file:  <br>\n",
    "#     ```python Strahler_Correction_execute.py```\n",
    "# 5) Plots should appear in python GUI windows - you can adjust plot positioning in this window, and save the figures. \n",
    "#       Follow the GUI instructions to correct loops.\n",
    "# 6) Click the \"Finish Correction\" button after finishing ALL corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 7 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed by Sam Kraus 12/16/24\n",
    "\n",
    "from Display_Orders import process_creek_orders\n",
    "\n",
    "# Load the variables from the JSON file\n",
    "with open(f\"OUTPUTS/{shortname}_processed_variables_Strahler_Correction.json\", \"r\") as f:\n",
    "    variables = json.load(f)\n",
    "\n",
    "skeleton = variables[\"skeleton\"]\n",
    "X = variables[\"X\"]\n",
    "Y = variables[\"Y\"]\n",
    "creek_order = variables[\"creek_order\"]\n",
    "creek_order_single = variables[\"creek_order_single\"]\n",
    "creek_order_swapped = variables[\"creek_order_swapped\"]\n",
    "creek_order_single_swapped = variables[\"creek_order_single_swapped\"]\n",
    "PTS = variables[\"PTS\"]\n",
    "order_max = variables[\"order_max\"]\n",
    "STRAHLER = variables[\"STRAHLER\"]\n",
    "# print('STRAHLER = ', STRAHLER)\n",
    "STRAIGHTDIST = variables[\"STRAIGHTDIST\"]\n",
    "IDXBRANCH = variables[\"IDXBRANCH\"]\n",
    "IDXSEG = variables[\"IDXSEG\"]\n",
    "\n",
    "def convert_to_numpy(data, dtype=None):\n",
    "    \"\"\"Safely convert input data to numpy array\"\"\"\n",
    "    try:\n",
    "        if isinstance(data, list):\n",
    "            # Handle nested lists by converting inner lists first\n",
    "            if data and isinstance(data[0], list):\n",
    "                data = [np.array(row) for row in data]\n",
    "        return np.array(data, dtype=dtype)\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting data to numpy array: {e}\")\n",
    "        print(\"Data sample:\", data[:2] if isinstance(data, list) else data)\n",
    "        raise\n",
    "\n",
    "# Convert to numpy arrays first\n",
    "skeleton = convert_to_numpy(skeleton, dtype=bool)\n",
    "X = convert_to_numpy(X, dtype=float)\n",
    "Y = convert_to_numpy(Y, dtype=float)\n",
    "X = X - np.nanmin(X)\n",
    "Y = Y - np.nanmin(Y)\n",
    "creek_order = convert_to_numpy(creek_order, dtype=float)\n",
    "creek_order_single = convert_to_numpy(creek_order, dtype=float)\n",
    "creek_order_swapped = convert_to_numpy(creek_order_swapped, dtype=float)\n",
    "creek_order_single_swapped = convert_to_numpy(creek_order_single_swapped, dtype=float)\n",
    "PTS = convert_to_numpy(PTS, dtype=bool)\n",
    "order_max = int(order_max)\n",
    "STRAHLER = convert_to_numpy(STRAHLER, dtype=float)\n",
    "# print('STRAHLER numpy = ', STRAHLER)\n",
    "STRAIGHTDIST = convert_to_numpy(STRAIGHTDIST, dtype=float)\n",
    "IDXBRANCH = convert_to_numpy(IDXBRANCH, dtype=float)\n",
    "IDXSEG = convert_to_numpy(IDXSEG, dtype=float)\n",
    "\n",
    "# Execute loaded Step 7 function\n",
    "SINUOSITY, STRAIGHTDIST, STRAHLER, SEGMENTS, SINUOUSLENGTH = process_creek_orders(STRAHLER, STRAIGHTDIST, Z, X, Y, creek_order_swapped, ID, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 8 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed by Sam Kraus 12/20/24\n",
    "\n",
    "from Process_CrossSections import process_xsects, process_xsects_diagnostic\n",
    "\n",
    "WIDTH, DEPTH, AREA = process_xsects(creekmask, creek, IDXSEG, ordermax, figview=False)\n",
    "\n",
    "# # diagnostic version: uncomment and run for debugging\n",
    "# WIDTH, DEPTH, AREA = process_xsects_diagnostic(creekmask, creek, skeleton, IDXSEG, ordermax, figview=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 9 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed by Sam Kraus 12/16/24\n",
    "\n",
    "from Process_JunctionAngles import process_junction_angles, process_junction_angles_diagnostic\n",
    "\n",
    "ANGLEORDER = process_junction_angles(skeleton, creekmask, Z, IDXBRANCH, SINUOUSLENGTH, SEGMENTS, fig_view=False)\n",
    "\n",
    "# # debugging option, uncomment to run:\n",
    "# ANGLEORDER = process_junction_angles_diagnostic(skeleton, creekmask, Z, IDXBRANCH, SINUOUSLENGTH, SEGMENTS, fig_view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 10 - CHIROL_CREEK_ALGORITHM_2024.m\n",
    "# written by Claude AI, reviewed by Sam Kraus 12/23/24\n",
    "\n",
    "from Save_Results import process_creek_morphometry, process_creek_morphometry_diagnostic\n",
    "\n",
    "SUMMARY_df, THRESHOLD_df, SINUOUSLENGTH, STRAIGHTDIST, SINUOSITY, DEPTH, WIDTH, AREA = process_creek_morphometry(\n",
    "                                                                                                                ANGLEORDER, ID, SEGMENTS, SINUOUSLENGTH, \n",
    "                                                                                                                SINUOSITY, WIDTH, DEPTH, AREA, STRAIGHTDIST, \n",
    "                                                                                                                shortname, Cth, LZth, HZth, Ctharea, LZtharea, HZtharea\n",
    "                                                                                                                )\n",
    "\n",
    "# # debugging version, uncomment to run\n",
    "# SUMMARY_df, THRESHOLD_df, SINUOUSLENGTH, STRAIGHTDIST, SINUOSITY, DEPTH, WIDTH, AREA = process_creek_morphometry_diagnostic(ANGLEORDER, ID, SEGMENTS, SINUOUSLENGTH, \n",
    "#                                  SINUOSITY, WIDTH, DEPTH, AREA, STRAIGHTDIST, \n",
    "#                                  shortname, Cth, LZth, HZth, Ctharea, LZtharea, HZtharea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TidalCreekAlg-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
